### **11.2 量化與剪枝技術的數學基礎**

在語言模型壓縮中，量化（Quantization）與剪枝（Pruning）技術用於減少模型大小、降低推理延遲和資源需求。它們的數學基礎如下：

---

### **1. 量化（Quantization）的數學基礎**

量化的目的是將高精度的浮點數（如 32 位浮點數）映射為低精度（如 8 位整數或浮點數）。這樣可顯著降低存儲和計算需求。

#### **1.1 量化函數**

假設原始權重矩陣為  $W$ ，量化過程用一個函數  $Q$  表示：

```math
\hat{W} = Q(W)

```
其中  $\hat{W}$  是量化後的權重矩陣。

#### **1.2 線性量化**

將浮點數數據標準化到固定範圍  $[w_{\text{min}}, w_{\text{max}}]$  並映射到離散整數值。對於  $w \in W$ ：

1. **標準化：**  

```math
   w_{\text{norm}} = \frac{w - w_{\text{min}}}{w_{\text{max}} - w_{\text{min}}}

```

2. **映射到整數：**  
   使用  $k$  位整數，離散化為：

```math
   w_{\text{quantized}} = \text{round}(w_{\text{norm}} \cdot (2^k - 1))

```

3. **解碼回浮點數：**  
   還原為近似值：

```math
   \hat{w} = w_{\text{quantized}} \cdot \frac{w_{\text{max}} - w_{\text{min}}}{2^k - 1} + w_{\text{min}}

```

#### **1.3 非線性量化**

非線性量化（如對數尺度）適用於動態範圍大的權重或激活值，使用非均勻的間隔分布：

- **對數尺度：**

```math
  \hat{w} = \text{round}(\log(w + \epsilon) \cdot (2^k - 1))

```

#### **1.4 量化誤差**

量化會引入誤差，定義如下：

```math
\epsilon = w - \hat{w}

```
其均方誤差為：

```math
\text{MSE} = \mathbb{E}[(w - \hat{w})^2]

```
在實踐中，透過校準和混合精度量化（如部分層保持高精度）可降低誤差。

---

### **2. 剪枝（Pruning）的數學基礎**

剪枝通過移除冗餘權重或神經元來減小模型大小。根據重要性測度進行裁剪。

#### **2.1 權重剪枝**

移除權重值接近零的元素。

1. **掩碼表示：**  
   使用二值掩碼  $M \in \{0, 1\}$  表示保留與移除的權重：

```math
   \hat{W} = W \odot M

```
   其中  $\odot$  表示逐元素乘法。

2. **重要性度量：**  
   -  $L_1$ -範數剪枝：權重值越小，重要性越低：

```math
     \text{Importance}(w_{ij}) = |w_{ij}|

```
   -  $L_2$ -範數剪枝：考慮權重向量的重要性：

```math
     \text{Importance}(W_i) = \|W_i\|_2

```

---

#### **2.2 結構化剪枝**

結構化剪枝直接移除某些神經元、通道或層，減少計算圖的複雜性。

- **剪枝目標：**  
  找到一個次優結構化模型  $f_{\text{pruned}}(x)$ ：

```math
  f_{\text{pruned}}(x) = \sum_{i \in S} w_i \cdot x_i

```
  其中  $S$  是保留的權重或神經元集合。

- **優化問題：**  
  在滿足性能約束的情況下，最大化稀疏性：

```math
  \min_{W} \mathcal{L}(W) + \lambda \|W\|_0

```
  其中  $\lambda$  控制稀疏性。

---

#### **2.3 剪枝後微調**

剪枝後模型需要微調以恢復性能，更新剩餘權重以補償剪枝帶來的損失：

```math
\min_{W_{\text{pruned}}} \mathcal{L}(W_{\text{pruned}})

```

---

### **3. 整合量化與剪枝**

量化與剪枝可結合使用以最大化壓縮效果，典型流程如下：

1. **剪枝後量化：**  
   將剪枝後的稀疏模型進行量化以進一步減少存儲需求。

2. **優化問題：**  
   同時優化稀疏性與精度，問題可表達為：

```math
   \min_{W, M} \mathcal{L}(W \odot M) + \lambda \|W\|_0 + \gamma \|Q(W)\|

```
   其中  $Q(W)$  表示量化誤差， $\lambda$  和  $\gamma$  控制剪枝與量化的權重。

---

### **4. 數學挑戰與實踐技巧**

- **剪枝與量化的交互：**  
  剪枝後模型可能有不均勻分布，會增加量化誤差。

- **混合精度策略：**  
  對重要的層使用高精度表示，其他層進行量化。

- **校準與重新訓練：**  
  利用校準數據調整參數分布，並重新訓練以提升壓縮後模型的性能。

---

量化與剪枝技術的數學基礎為實現高效模型壓縮提供了理論支持。在語言模型部署中，這些技術是應對計算資源限制的關鍵手段。