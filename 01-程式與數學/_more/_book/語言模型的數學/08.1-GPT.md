
#### **8.1 預測式語言模型（例如 GPT）**

生成式語言模型的核心任務是預測下一個詞或一個序列中缺失的部分。這類模型的主要思想是，給定一段已知的文本，學習模型能夠生成下一個詞或整段文本，從而實現語言生成的任務。GPT 就是這種預測式語言模型的代表。

在討論 GPT 的數學基礎之前，我們首先了解預測式語言模型的一般數學形式。

---

#### **8.1.1 預測式語言模型的數學基礎**

預測式語言模型的目標是學習一個條件概率分佈  $P(w_1, w_2, \dots, w_T)$ ，其中  $w_1, w_2, \dots, w_T$  是一段文本中的詞語。這個模型的目的是學習如何基於前文生成或預測後面的詞語。根據鏈式法則，對於一個詞序列的概率可以表示為：


```math
P(w_1, w_2, \dots, w_T) = \prod_{t=1}^{T} P(w_t | w_1, w_2, \dots, w_{t-1})

```

這裡， $P(w_t | w_1, w_2, \dots, w_{t-1})$  是給定前文的條件概率，表示在前面已知的詞語下，生成當前詞語  $w_t$  的概率。模型的目標是最大化這個條件概率的對數似然：


```math
\mathcal{L} = \sum_{t=1}^{T} \log P(w_t | w_1, w_2, \dots, w_{t-1})

```

在這裡， $\mathcal{L}$  是我們希望最大化的目標函數。對於語言模型來說，這通常意味著學習如何預測給定前文的單詞。

---

#### **8.1.2 GPT 模型的數學框架**

GPT（Generative Pretrained Transformer）是一個基於 Transformer 的自回歸模型。其運作原理基於自回歸模型的概念，簡單來說，就是它每次生成一個詞，並將其作為下一次預測的上下文。GPT 模型的架構可以分為兩個階段：預訓練和微調。

1. **預訓練**：
   
   在預訓練階段，GPT 使用大量的無標註文本來學習語言的統計特徵。具體來說，GPT 訓練的目標是最大化上述的對數似然，這意味著它學習如何根據前文的上下文預測下一個詞。在這一過程中，GPT 會利用大規模的文本數據來學習語言模式，而不需要手動標註的數據。

   具體來說，GPT 使用 Transformer 的架構來建模序列的條件概率。假設  $x_1, x_2, \dots, x_T$  是一段文本的單詞序列，則 GPT 的預測可以表示為：


```math
   P(w_t | w_1, w_2, \dots, w_{t-1}) = \text{Softmax}(W_2 \cdot \text{LayerNorm}(f_{\theta}(w_1, w_2, \dots, w_{t-1})))

```

   其中， $f_{\theta}$  是 Transformer 模型的運算過程， $W_2$  是最終投影矩陣，將 Transformer 的輸出映射到詞表的維度，Softmax 函數則用來計算每個詞的預測概率。

2. **微調**：

   預訓練後，GPT 可以進行微調，以適應特定任務的需求。微調通常是在標註數據上進行，並且可以通過最小化特定任務的損失函數來達成。微調階段讓 GPT 能夠根據特定領域或應用來調整其參數，以便更好地完成特定的任務。

---

#### **8.1.3 自回歸模型與生成過程**

GPT 是一個自回歸模型，這意味著它每次生成一個詞，並將這個生成的詞加入到已經生成的文本中，作為生成下一個詞的上下文。具體來說，給定一個部分生成的文本  $w_1, w_2, \dots, w_{t-1}$ ，GPT 的目標是預測下一个詞  $w_t$ 。生成過程中的每一步，都基於前面的詞進行推理，這是自回歸的特點。

這個過程的數學可以表達為：


```math
P(w_t | w_1, w_2, \dots, w_{t-1}) = \text{Softmax}(W_2 \cdot f_{\theta}(w_1, w_2, \dots, w_{t-1}))

```

其中，Softmax 操作對應於詞表中的每一個詞，並根據前文計算出對應的概率，然後根據這些概率選擇生成的詞。

生成過程持續進行，直到達到預定的序列長度或遇到結束符。

---

#### **8.1.4 GPT 中的注意力機制與自注意力**

在 GPT 模型中，**自注意力機制（Self-Attention）** 是核心技術之一。自注意力機制允許模型在生成每個詞時，根據序列中的其他詞來加權並處理這些詞的信息。這種機制使得 GPT 能夠在大範圍的上下文中捕捉長距離的依賴關係。

數學上，自注意力的計算可以表示為：


```math
\text{Attention}(Q, K, V) = \text{Softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right) V

```

其中， $Q$ ,  $K$ , 和  $V$  分別是查詢（Query）、鍵（Key）和值（Value）矩陣， $d_k$  是鍵的維度。通過自注意力機制，模型能夠根據序列中每個位置的上下文來調整權重，進而生成更加合理的輸出。

---

#### **8.1.5 小結**

預測式語言模型（如 GPT）是基於自回歸模型的生成式語言模型，它通過最大化條件概率來學習語言模式。GPT 使用 Transformer 架構，其中自注意力機制是其關鍵組成部分，幫助模型捕捉長距離的依賴關係。預訓練和微調是 GPT 訓練過程中的兩個主要階段，預訓練階段讓模型學習語言的統計特徵，而微調階段則讓模型適應特定任務。這些技術和方法共同作用，使得 GPT 成為當前最強大的生成式語言模型之一。